import mediapipe as mp
import cv2
import numpy as np


class Pipe():

    """
    Setting up mediapipe class. Mediapipe holistic is used to process images and extract
    keypoint landmarks which are used in training and inference of neural network.
    """

    def __init__(self, frames_per_seq = 40, num_sample_videos = 30):

        # Instantiate mp holistic
        self.mp_holistic = mp.solutions.holistic

        # Instantiate drawing utils
        self.mp_drawing = mp.solutions.drawing_utils

        # Set how many frames should be collected/analyzed for training and inference
        self.frames_per_seq = frames_per_seq
        self.num_sample_videos = num_sample_videos

    def pose_detection(self, image, model):
        """
        :param image: Image frame to pass through to the provided model for object detection.
        :param model: The model to use for object detection on the image. Model used in this program is mediapipe's
                        Holistic() model.
        :return: The image frame and the resulting keypoint landmarks from the object detection if a person is found.
        """
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert color to RGB
        image.flags.writeable = False                   # image no longer writeable to speed up prediction
        results = model.process(image)                  # process image
        image.flags.writeable = True                    # image is now writeable again
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # convert color back
        return image, results

    def draw_landmarks(self, image, results):
        """"
        Image: An image frame that has been processed by the mp.mp_holistic.Holistic() model and that you wish to
        draw key landmarks on.
        Results: Are the landmark results generated by the Holistic() model to be drawn on the image frame.
        Returns: Does not return anything but draws the face, pose, and left/right landmarks on the image frame
        """
        self.mp_drawing.draw_landmarks(image, results.face_landmarks, self.mp_holistic.FACEMESH_TESSELATION,
                                       self.mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),
                                       self.mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))
        self.mp_drawing.draw_landmarks(image, results.pose_landmarks, self.mp_holistic.POSE_CONNECTIONS,
                                       self.mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=2),
                                       self.mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))
        self.mp_drawing.draw_landmarks(image, results.left_hand_landmarks, self.mp_holistic.HAND_CONNECTIONS,
                                       self.mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=2),
                                       self.mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))
        self.mp_drawing.draw_landmarks(image, results.right_hand_landmarks, self.mp_holistic.HAND_CONNECTIONS,
                                       self.mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),
                                       self.mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))

    def extract_landmarks(self, results):
        """
        extract_landmarks takes in the results from processing an image with mediapipe.mp_holistic.Holistic.process(),
        and extracts the landmark values for pose, face, left & right hand. If no landmarks exist, which will happen
        if the given body part is out of frame, then an empty array of zeros, with the same shape, will be created
        in its place.

        :param results: detection results returned from mediapipe.mp_holistic.Holistic.process()
        :return: One 1D numpy array which is the concatenation of four flattened 1D numpy arrays,
        which include the values (x, y, & z co-ordinates) of every pose, face, and hand landmark. Pose landmarks
        include an additional visibility parameter. Final array has a shape of (1662, )
        """
        # Extract landmarks
        # Extract pose landmarks -> 33 pose landmarks with an x, y, z & visibility value (132 inputs).
        # Loop through every pose landmark and extract and append its x, y, z, and visibility values. The 4 values
        # are stored in a list, before appending to main list creating a 33x4 array. Array is then flattened to
        # a one dimensional np array. If there is no one in the frame then we pass through an empty array of zeros.
        pose_landmarks = (np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).
                          flatten() if results.pose_landmarks else np.zeros(132))

        # extract face landmarks -> There are 468 face landmarks with x, y, z values (1404 inputs)
        # same methodology as pose landmarks
        face_landmarks = (np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).
                          flatten() if results.face_landmarks else np.zeros(1404))

        # extract left hand landmarks -> There are 21 landmarks with x, y, & z values (63 inputs)
        left_hand_landmarks = (np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).
                               flatten() if results.left_hand_landmarks else np.zeros(63))

        # extract right hand landmarks -> There are 21 landmarks with x, y, & z values (63 inputs)
        right_hand_landmarks = (np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).
                                flatten() if results.right_hand_landmarks else np.zeros(63))


        return np.concatenate([pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks])

    # reshape face & hand landmarks so face will be a 468 (row) x 3 (col) array, and hand
    # array will be back in its original 21 (row) x 3 (col) array.
    # From here we need to calculate the distance between select right hand landmarks, select right hand landmarks and
    # left hand landmarks, and select right hand landmarks and face landmarks.
    # New inter-right hand distances calculated: 21**21=441
    # New right-left hand distances calculated: 21*21 = 441
    # New right hand face distances calculated:

    def three_d_distance(self, pointa, pointb):
        ax, ay, az = pointa
        bx, by, bz = pointb
        distance = ((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)**(1/2)
        return distance


    def extract_landmarks2(self, results):
        """
        Extract key landmarks but maintain original shape (i.e. not flattened)

        extract_landmarks takes in the results from processing an image with mediapipe.mp_holistic.Holistic.process(),
        and extracts the landmark values for pose, face, left & right hand. If no landmarks exist, which will happen
        if the given body part is out of frame, then an empty array of zeros, with the same shape, will be created
        in its place.

        :param results: detection results returned from mediapipe.mp_holistic.Holistic.process()
        :return: Four numpy arrays for each body part detection. Each data landmark point has a corresponding
        x, y, & z co-ordinates. The Pose landmarks include an additional visibility parameter. Final array has a shape of (1662, )
        """
        # Extract landmarks
        # Extract pose landmarks -> 33 pose landmarks with an x, y, z & visibility value (132 inputs).
        # Loop through every pose landmark and extract and append its x, y, z, and visibility values. The 4 values
        # are stored in a list, before appending to main list creating a 33x4 array. Array is then flattened to
        # a one dimensional np array. If there is no one in the frame then we pass through an empty array of zeros.
        pose_landmarks = (np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark])
                          if results.pose_landmarks else np.zeros(132))

        # extract face landmarks -> There are 468 face landmarks with x, y, z values (1404 inputs)
        # same methodology as pose landmarks
        face_landmarks = (np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark])
                          if results.face_landmarks else np.zeros(1404))

        # extract left hand landmarks -> There are 21 landmarks with x, y, & z values (63 inputs)
        left_hand_landmarks = (np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark])
                               if results.left_hand_landmarks else np.zeros(63))

        # extract right hand landmarks -> There are 21 landmarks with x, y, & z values (63 inputs)
        right_hand_landmarks = (np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark])
                                if results.right_hand_landmarks else np.zeros(63))


        return np.concatenate(pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks)
